# ğŸ”­ Overview â€“ AI Gesture Control for 3D Workflows

**Description:**
MotionCoder turns **sensor streams** into **semantic gestures/intents** in real time, then routes them to your **target software** via lightweight connectors.
The stack is **modular** (Sensors â†’ AI Interpretation â†’ Connectors), **low-latency**, and optimized for **CAD/DCC**â€”yet portable to many other domains.

## ğŸ¥ Layer 1 â€“ Sensor I/O

| ğŸ§© **Module**       | ğŸ“ **Short Description**                                          | ğŸ”Œ **Hardware/Dependencies**               | âš–ï¸ **License** | âš ï¸ **Notes**                             | ğŸš¦ **Status**            | ğŸ”— **Link**                                                                |
| ------------------- | ------------------------------------------------------------------ | ------------------------------------------- | -------------- | ----------------------------------------- | ------------------------- | -------------------------------------------------------------------------- |
| **MVCore3D**        | Anipose + MMPose stack with CPU tuning for optimal performance.    | Various cameras (incl. low-cost), sync, PTZ | Apache-2.0     | â€”                                         | ğŸŸ¡ Planned                | coming soon   |
| **Leap2Pose**       | **LeapC** ingestion â†’ normalized poses/streams.                    | Leap Motion (Controller 1/2)                | MIT            | â€”                                         | ğŸŸ¢ Active                 | coming soon |
| **MVMono3D**        | Mono multi-camera pipeline (high perf, high occlusion robustness). | 3â€“4 mono cams, IR/filter, sync              | Apache-2.0     | â€”                                         | ğŸŸ  Targeted for next year | coming soon  |
| **TDMStrobe**       | Time-Division-Multiplexed IR strobe + camera trigger               | IR-LED arrays, MOSFET drivers, MCU          | Apache-2.0     | Designed for **MVCore3D** & **MVMono3D**  | ğŸŸ¡ Planned                | coming soon   |

## ğŸ§  Layer 2 â€“ AI Interpretation (Pose â†’ Intents/Gestures)

| ğŸ§© **Module**        | ğŸ“ **Short Description**                                 | ğŸ” **I/O**                  | âš–ï¸ **License** | âš ï¸ **Notes** | ğŸš¦ **Status**  | ğŸ”— **Link**                                                                   |
| -------------------- | --------------------------------------------------------- | ---------------------------- | -------------- | ------------ | -------------- | ------------------------------------------------------------------------------ |
| **MotionCoder**      | Real-time gestures/intents, state machine, context logic. | Poses/keypoints from Layer 1 | Apache-2.0     | â€”            | ğŸŸ¡ In progress | [MotionCoder](https://github.com/xtanai/motioncoder) |
| **Pose2Gizmo**       | Poses â†’ 3D manipulator/gizmo commands & visualization.    | Normalized poses, tool hints | MIT            | â€”            | ğŸŸ¡ Planned     | coming soon   |

## ğŸ”— Layer 3 â€“ Connectors (DCC/CAD/Engines)

| ğŸ§© **Module**           | ğŸ“ **Short Description**                               | ğŸ–¥ï¸ **Target System** | âš–ï¸ **License** | âš ï¸ **Notes** | ğŸš¦ **Status**                 | ğŸ”— **Link**                                                                         |
| ------------------------ | ------------------------------------------------------ | --------------------- | -------------- | ------------ | ----------------------------- | ------------------------------------------------------------------------------------ |
| **Coder2Blender**        | Add-on/API bridge: gestures â†’ operators/hotkeys/nodes. | Blender               | MIT            | â€”            | ğŸŸ¡ Research (API exploration) | coming soon  |
| **Coder2Unreal**         | Plugin/bridge: gestures â†’ Blueprint/C++ events.        | Unreal Engine         | MIT            | â€”            | ğŸŸ¡ Planned                    | coming soon   |
| **Coder2Dassault**       | Macro/API bridge: gestures â†’ CAD commands.             | Dassault (SWX/CATIA)  | MIT            | â€”            | ğŸŸ  Targeted for next year     | coming soon |


**Why separate (MotionCoder â†” Coder2#)?**

* **Modularity:** MotionCoder (detection/semantics) remains independent of any target application.
* **Reuse:** One semantics engine, many **Coder2#** adapters (CAD, DCC, and beyond).
* **Breadth:** **100+ potential software targets** (integrations), far beyond the examples shown here.
* **Maintainability & Scale:** Target-API changes impact only the relevant **Coder2#**, not the core.
* **Portability:** Faster rollout to **new applications**â€”e.g., sign-language assistanceâ€”beyond CAD/DCC.



## ğŸ¥ Recommended Sensors

Choose from three sensor modules â€” **MVCore3D**, **Leap2Pose**, and **MVMono3D** â€” based on your **budget** and target **quality**, with matching **hardware recommendations**. More in the GitHub docs: ğŸ‘‰ [Sensor Guide](https://github.com/xtanai/sensor-guide)


## ğŸ—ºï¸ Roadmap

Coming soon. ğŸš€
